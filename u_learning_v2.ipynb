{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_adult():\n",
    "    \"\"\"Load and preprocess the Adult dataset.\"\"\"\n",
    "    adult = fetch_ucirepo(id=2)\n",
    "    x_adult = adult.data.features.copy()\n",
    "    y_adult = adult.data.targets.copy()\n",
    "    y_adult['income'] = y_adult['income'].str.strip('.')\n",
    "    adult_data = pd.concat([x_adult, y_adult], axis=1)\n",
    "    \n",
    "    for column in ['workclass', 'occupation', 'native-country']:\n",
    "        adult_data.loc[adult_data[column] == '?', column] = float('nan')\n",
    "        mode_value = adult_data[column].mode()[0]\n",
    "        adult_data.loc[:, column] = adult_data[column].fillna(mode_value)\n",
    "    \n",
    "    label = LabelEncoder()\n",
    "    adult_data['sex'] = label.fit_transform(adult_data['sex'])\n",
    "    adult_data['income'] = label.fit_transform(adult_data['income'])\n",
    "    adult_data = pd.get_dummies(adult_data, columns=['workclass', 'marital-status', 'education', 'occupation', 'relationship', 'race', 'native-country'], drop_first=True)\n",
    "    \n",
    "    X_adult = adult_data.drop('income', axis=1)\n",
    "    y_adult = adult_data['income']\n",
    "    \n",
    "    return X_adult, y_adult\n",
    "\n",
    "def load_and_preprocess_bank():\n",
    "    \"\"\"Load and preprocess the Bank Marketing dataset.\"\"\"\n",
    "    bank_marketing = fetch_ucirepo(id=222)\n",
    "    x_bank = bank_marketing.data.features.copy()\n",
    "    y_bank = bank_marketing.data.targets.copy()\n",
    "    bank_data = pd.concat([x_bank, y_bank], axis=1)\n",
    "    \n",
    "    for column in ['job', 'contact', 'poutcome']:\n",
    "        mode_value = bank_data[column].mode()[0]\n",
    "        bank_data.loc[:, column] = bank_data[column].fillna(mode_value)\n",
    "    \n",
    "    bank_data = pd.get_dummies(bank_data, columns=['job', 'marital', 'education', 'month', 'poutcome'], drop_first=True)\n",
    "    binary_columns = ['default', 'housing', 'loan', 'contact', 'y']\n",
    "    label = LabelEncoder()\n",
    "    for col in binary_columns:\n",
    "        bank_data[col] = label.fit_transform(bank_data[col])\n",
    "    \n",
    "    X_bank = bank_data.drop('y', axis=1)\n",
    "    y_bank = bank_data['y']\n",
    "    \n",
    "    return X_bank, y_bank\n",
    "# Load and preprocess datasets\n",
    "X_adult, y_adult = load_and_preprocess_adult()\n",
    "X_bank, y_bank = load_and_preprocess_bank()\n",
    "\n",
    "# Split datasets\n",
    "X_adult_train, X_adult_test, y_adult_train, y_adult_test = train_test_split(X_adult, y_adult, test_size=0.20, random_state=42)\n",
    "X_bank_train, X_bank_test, y_bank_train, y_bank_test = train_test_split(X_bank, y_bank, test_size=0.20, random_state=43)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_adult_train = scaler.fit_transform(X_adult_train)\n",
    "X_adult_test = scaler.transform(X_adult_test)\n",
    "X_bank_train = scaler.fit_transform(X_bank_train)\n",
    "X_bank_test = scaler.transform(X_bank_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_adult_train, y_adult_train = smote.fit_resample(X_adult_train, y_adult_train)\n",
    "X_bank_train, y_bank_train = smote.fit_resample(X_bank_train, y_bank_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(X, n_clusters=5):\n",
    "    \"\"\"Perform K-Means clustering.\"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    return labels, kmeans\n",
    "\n",
    "def em_clustering(X, n_components=5):\n",
    "    \"\"\"Perform Expectation Maximization clustering using Gaussian Mixture Models.\"\"\"\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    return labels, gmm\n",
    "\n",
    "def evaluate_clustering(X, labels):\n",
    "    \"\"\"Evaluate clustering results using silhouette score and Calinski-Harabasz index.\"\"\"\n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "    return silhouette, calinski_harabasz\n",
    "\n",
    "def plot_clusters(X, labels, title):\n",
    "    \"\"\"Plot clustering results.\"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=labels, palette=\"viridis\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Perform clustering on Adult dataset\n",
    "adult_kmeans_labels, adult_kmeans = kmeans_clustering(X_adult_train)\n",
    "adult_em_labels, adult_em = em_clustering(X_adult_train)\n",
    "\n",
    "# Perform clustering on Bank dataset\n",
    "bank_kmeans_labels, bank_kmeans = kmeans_clustering(X_bank_train)\n",
    "bank_em_labels, bank_em = em_clustering(X_bank_train)\n",
    "\n",
    "# Evaluate and plot clustering results\n",
    "for dataset, kmeans_labels, em_labels in [('Adult', adult_kmeans_labels, adult_em_labels),\n",
    "                                          ('Bank', bank_kmeans_labels, bank_em_labels)]:\n",
    "    X = X_adult_train if dataset == 'Adult' else X_bank_train\n",
    "    \n",
    "    kmeans_silhouette, kmeans_ch = evaluate_clustering(X, kmeans_labels)\n",
    "    em_silhouette, em_ch = evaluate_clustering(X, em_labels)\n",
    "    \n",
    "    print(f\"\\nClustering Evaluation for {dataset} dataset:\")\n",
    "    print(f\"K-Means - Silhouette: {kmeans_silhouette:.4f}, Calinski-Harabasz: {kmeans_ch:.4f}\")\n",
    "    print(f\"EM      - Silhouette: {em_silhouette:.4f}, Calinski-Harabasz: {em_ch:.4f}\")\n",
    "    \n",
    "    plot_clusters(X, kmeans_labels, f\"K-Means Clustering on {dataset} Dataset\")\n",
    "    plot_clusters(X, em_labels, f\"EM Clustering on {dataset} Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reduction(X, n_components=2):\n",
    "    \"\"\"Perform PCA dimensionality reduction.\"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    explained_variance_ratio = pd.DataFrame({\n",
    "        'Principal Component': range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "        'Explained Variance Ratio': pca.explained_variance_ratio_\n",
    "    })\n",
    "    return X_reduced, explained_variance_ratio, pca\n",
    "\n",
    "def ica_reduction(X, n_components=2):\n",
    "    \"\"\"Perform ICA dimensionality reduction.\"\"\"\n",
    "    ica = FastICA(n_components=n_components, random_state=42)\n",
    "    X_reduced = ica.fit_transform(X)\n",
    "    kurtosis_values = pd.DataFrame({\n",
    "        'Component': range(1, X_reduced.shape[1] + 1),\n",
    "        'Kurtosis': pd.DataFrame(X_reduced).kurtosis()\n",
    "    })\n",
    "    return X_reduced, kurtosis_values, ica\n",
    "\n",
    "def rp_reduction(X, n_components=2):\n",
    "    \"\"\"Perform Random Projection dimensionality reduction.\"\"\"\n",
    "    rp = GaussianRandomProjection(n_components=n_components, random_state=42)\n",
    "    X_reduced = rp.fit_transform(X)\n",
    "    X_reconstructed = np.dot(X_reduced, np.linalg.pinv(rp.components_.T))\n",
    "    reconstruction_error = np.mean(np.square(X - X_reconstructed))\n",
    "    reconstruction_error_df = pd.DataFrame({\n",
    "        'Metric': ['Reconstruction Error'],\n",
    "        'Value': [reconstruction_error]\n",
    "    })\n",
    "    return X_reduced, reconstruction_error_df, rp\n",
    "\n",
    "# Perform dimensionality reduction\n",
    "for dataset, X in [('Adult', X_adult_train), ('Bank', X_bank_train)]:\n",
    "    print(f\"\\nDimensionality Reduction Results for {dataset} dataset:\")\n",
    "    \n",
    "    X_pca, pca_explained_variance, _ = pca_reduction(X)\n",
    "    X_ica, ica_kurtosis, _ = ica_reduction(X)\n",
    "    X_rp, rp_reconstruction_error, _ = rp_reduction(X)\n",
    "    \n",
    "    print(\"PCA Explained Variance Ratio:\")\n",
    "    print(pca_explained_variance)\n",
    "    \n",
    "    print(\"\\nICA Kurtosis:\")\n",
    "    print(ica_kurtosis)\n",
    "    \n",
    "    print(\"\\nRP Reconstruction Error:\")\n",
    "    print(rp_reconstruction_error)\n",
    "    \n",
    "    # Visualize reduced data\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "    plt.title(f\"PCA Reduction - {dataset}\")\n",
    "    plt.subplot(132)\n",
    "    plt.scatter(X_ica[:, 0], X_ica[:, 1])\n",
    "    plt.title(f\"ICA Reduction - {dataset}\")\n",
    "    plt.subplot(133)\n",
    "    plt.scatter(X_rp[:, 0], X_rp[:, 1])\n",
    "    plt.title(f\"RP Reduction - {dataset}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering on Dimensionality-Reduced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing clustering on dimensionality-reduced data:\")\n",
    "\n",
    "for dataset, X_train in [('Adult', X_adult_train), ('Bank', X_bank_train)]:\n",
    "    print(f\"\\n{dataset} Dataset:\")\n",
    "    \n",
    "    # PCA\n",
    "    X_pca, _, _ = pca_reduction(X_train)\n",
    "    kmeans_labels_pca = kmeans_clustering(X_pca)[0]\n",
    "    em_labels_pca = em_clustering(X_pca)[0]\n",
    "    print(\"PCA:\")\n",
    "    print(f\"  KMeans Silhouette Score: {silhouette_score(X_pca, kmeans_labels_pca):.4f}\")\n",
    "    print(f\"  EM Silhouette Score: {silhouette_score(X_pca, em_labels_pca):.4f}\")\n",
    "    \n",
    "    # ICA\n",
    "    X_ica, _, _ = ica_reduction(X_train)\n",
    "    kmeans_labels_ica = kmeans_clustering(X_ica)[0]\n",
    "    em_labels_ica = em_clustering(X_ica)[0]\n",
    "    print(\"ICA:\")\n",
    "    print(f\"  KMeans Silhouette Score: {silhouette_score(X_ica, kmeans_labels_ica):.4f}\")\n",
    "    print(f\"  EM Silhouette Score: {silhouette_score(X_ica, em_labels_ica):.4f}\")\n",
    "    \n",
    "    # Random Projection\n",
    "    X_rp, _, _ = rp_reduction(X_train)\n",
    "    kmeans_labels_rp = kmeans_clustering(X_rp)[0]\n",
    "    em_labels_rp = em_clustering(X_rp)[0]\n",
    "    print(\"Random Projection:\")\n",
    "    print(f\"  KMeans Silhouette Score: {silhouette_score(X_rp, kmeans_labels_rp):.4f}\")\n",
    "    print(f\"  EM Silhouette Score: {silhouette_score(X_rp, em_labels_rp):.4f}\")\n",
    "\n",
    "    # Visualize clustering results on reduced data\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # KMeans\n",
    "    plt.subplot(231)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels_pca, cmap='viridis')\n",
    "    plt.title(f'KMeans on PCA-reduced {dataset} Data')\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    plt.scatter(X_ica[:, 0], X_ica[:, 1], c=kmeans_labels_ica, cmap='viridis')\n",
    "    plt.title(f'KMeans on ICA-reduced {dataset} Data')\n",
    "    \n",
    "    plt.subplot(233)\n",
    "    plt.scatter(X_rp[:, 0], X_rp[:, 1], c=kmeans_labels_rp, cmap='viridis')\n",
    "    plt.title(f'KMeans on RP-reduced {dataset} Data')\n",
    "    \n",
    "    # EM\n",
    "    plt.subplot(234)\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=em_labels_pca, cmap='viridis')\n",
    "    plt.title(f'EM on PCA-reduced {dataset} Data')\n",
    "    \n",
    "    plt.subplot(235)\n",
    "    plt.scatter(X_ica[:, 0], X_ica[:, 1], c=em_labels_ica, cmap='viridis')\n",
    "    plt.title(f'EM on ICA-reduced {dataset} Data')\n",
    "    \n",
    "    plt.subplot(236)\n",
    "    plt.scatter(X_rp[:, 0], X_rp[:, 1], c=em_labels_rp, cmap='viridis')\n",
    "    plt.title(f'EM on RP-reduced {dataset} Data')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train and evaluate a neural network classifier.\"\"\"\n",
    "    nn = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', alpha=0.001,\n",
    "                       learning_rate_init=0.001, max_iter=1000, random_state=43)\n",
    "    nn.fit(X_train, y_train)\n",
    "    train_score = nn.score(X_train, y_train)\n",
    "    test_score = nn.score(X_test, y_test)\n",
    "    return nn, train_score, test_score\n",
    "\n",
    "# Lists to store results for plotting\n",
    "datasets = []\n",
    "methods = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Train and evaluate NN on original and reduced data\n",
    "for dataset, X_train, y_train, X_test, y_test in [\n",
    "    ('Adult', X_adult_train, y_adult_train, X_adult_test, y_adult_test),\n",
    "    ('Bank', X_bank_train, y_bank_train, X_bank_test, y_bank_test)\n",
    "]:\n",
    "    print(f\"\\nNeural Network Performance on {dataset} dataset:\")\n",
    "    \n",
    "    # Original data\n",
    "    _, train_score, test_score = train_nn(X_train, y_train, X_test, y_test)\n",
    "    print(f\"Original Data - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('Original')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    # PCA reduced data\n",
    "    X_pca, _, pca = pca_reduction(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    _, train_score, test_score = train_nn(X_pca, y_train, X_test_pca, y_test)\n",
    "    print(f\"PCA Reduced  - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('PCA')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    # ICA reduced data\n",
    "    X_ica, _, ica = ica_reduction(X_train)\n",
    "    X_test_ica = ica.transform(X_test)\n",
    "    _, train_score, test_score = train_nn(X_ica, y_train, X_test_ica, y_test)\n",
    "    print(f\"ICA Reduced  - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('ICA')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    # RP reduced data\n",
    "    X_rp, _, rp = rp_reduction(X_train)\n",
    "    X_test_rp = rp.transform(X_test)\n",
    "    _, train_score, test_score = train_nn(X_rp, y_train, X_test_rp, y_test)\n",
    "    print(f\"RP Reduced   - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('RP')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'Dataset': datasets,\n",
    "    'Method': methods,\n",
    "    'Train Score': train_scores,\n",
    "    'Test Score': test_scores\n",
    "})\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Dataset', y='value', hue='Method', \n",
    "            data=pd.melt(results_df, id_vars=['Dataset', 'Method'], var_name='Score Type', value_name='value'),\n",
    "            ci=None)\n",
    "plt.title('Neural Network Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Method', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Clustering Labels as Features and Retraining NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cluster_labels(X, labels):\n",
    "    \"\"\"Add cluster labels as a new feature to the dataset.\"\"\"\n",
    "    return np.column_stack((X, labels))\n",
    "\n",
    "# Lists to store results for plotting\n",
    "datasets = []\n",
    "methods = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Add clustering labels and retrain NN\n",
    "for dataset, X_train, y_train, X_test, y_test in [\n",
    "    ('Adult', X_adult_train, y_adult_train, X_adult_test, y_adult_test),\n",
    "    ('Bank', X_bank_train, y_bank_train, X_bank_test, y_bank_test)\n",
    "]:\n",
    "    print(f\"\\nNeural Network Performance with Clustering Features on {dataset} dataset:\")\n",
    "    \n",
    "    # Original data (baseline)\n",
    "    _, train_score, test_score = train_nn(X_train, y_train, X_test, y_test)\n",
    "    print(f\"Original    - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('Original')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    # KMeans clustering\n",
    "    kmeans_labels, kmeans = kmeans_clustering(X_train)\n",
    "    X_train_kmeans = add_cluster_labels(X_train, kmeans_labels)\n",
    "    X_test_kmeans = add_cluster_labels(X_test, kmeans.predict(X_test))\n",
    "    _, train_score, test_score = train_nn(X_train_kmeans, y_train, X_test_kmeans, y_test)\n",
    "    print(f\"With KMeans - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('KMeans')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    # EM clustering\n",
    "    em_labels, em = em_clustering(X_train)\n",
    "    X_train_em = add_cluster_labels(X_train, em_labels)\n",
    "    X_test_em = add_cluster_labels(X_test, em.predict(X_test))\n",
    "    _, train_score, test_score = train_nn(X_train_em, y_train, X_test_em, y_test)\n",
    "    print(f\"With EM     - Train: {train_score:.4f}, Test: {test_score:.4f}\")\n",
    "    datasets.append(dataset)\n",
    "    methods.append('EM')\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "    # Visualize the distribution of cluster labels\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    sns.countplot(x=kmeans_labels)\n",
    "    plt.title(f'Distribution of KMeans Cluster - {dataset} Dataset')\n",
    "    plt.xlabel('KMeans Cluster')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    sns.countplot(x=em_labels)\n",
    "    plt.title(f'Distribution of EM Cluster - {dataset} Dataset')\n",
    "    plt.xlabel('EM Cluster')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize the relationship between cluster labels and target variable\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    sns.boxplot(x=kmeans_labels, y=y_train)\n",
    "    plt.title(f'KMeans Clusters vs Target Variable - {dataset} Dataset')\n",
    "    plt.xlabel('KMeans Cluster')\n",
    "    plt.ylabel('Target Variable')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    sns.boxplot(x=em_labels, y=y_train)\n",
    "    plt.title(f'EM Clusters vs Target Variable - {dataset} Dataset')\n",
    "    plt.xlabel('EM Cluster')\n",
    "    plt.ylabel('Target Variable')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'Dataset': datasets,\n",
    "    'Method': methods,\n",
    "    'Train Score': train_scores,\n",
    "    'Test Score': test_scores\n",
    "})\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Dataset', y='value', hue='Method', \n",
    "            data=pd.melt(results_df, id_vars=['Dataset', 'Method'], var_name='Score Type', value_name='value'),\n",
    "            ci=None)\n",
    "plt.title('Neural Network Performance with Clustering Features')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Method', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few more visualizations to better understand our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA explained variance ratio\n",
    "for dataset, X in [('Adult', X_adult_train), ('Bank', X_bank_train)]:\n",
    "    _, pca_explained_variance, _ = pca_reduction(X, n_components=10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(pca_explained_variance['Principal Component'], pca_explained_variance['Explained Variance Ratio'], 'bo-')\n",
    "    plt.title(f'PCA Explained Variance Ratio - {dataset} Dataset')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize ICA kurtosis\n",
    "for dataset, X in [('Adult', X_adult_train), ('Bank', X_bank_train)]:\n",
    "    _, ica_kurtosis, _ = ica_reduction(X, n_components=10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(ica_kurtosis['Component'], ica_kurtosis['Kurtosis'])\n",
    "    plt.title(f'ICA Component Kurtosis - {dataset} Dataset')\n",
    "    plt.xlabel('ICA Component')\n",
    "    plt.ylabel('Kurtosis')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize clustering results with PCA\n",
    "for dataset, X, kmeans_labels, em_labels in [\n",
    "    ('Adult', X_adult_train, adult_kmeans_labels, adult_em_labels),\n",
    "    ('Bank', X_bank_train, bank_kmeans_labels, bank_em_labels)\n",
    "]:\n",
    "    X_pca, _, _ = pca_reduction(X, n_components=2)\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(121)\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=kmeans_labels, palette=\"viridis\")\n",
    "    plt.title(f'K-Means Clustering on PCA-reduced {dataset} Dataset')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=em_labels, palette=\"viridis\")\n",
    "    plt.title(f'EM Clustering on PCA-reduced {dataset} Dataset')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
